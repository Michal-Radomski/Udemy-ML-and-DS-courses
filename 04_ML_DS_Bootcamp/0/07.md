Model evaluation in machine learning assesses how well a trained model performs on unseen data, using metrics to gauge its
predictive power and generalization ability. [iguazio](https://www.iguazio.com/glossary/model-evaluation/)

## Core Purpose

It identifies strengths like accuracy and weaknesses such as overfitting, where models memorize training data but fail on new
inputs. This step ensures reliability before deployment, preventing costly errors in real-world use.
[appliedaicourse](https://www.appliedaicourse.com/blog/model-evaluation-in-machine-learning/)

## Key Methods

Common techniques include hold-out validation, splitting data into train/test sets, and k-fold cross-validation, which
divides data into k subsets for repeated testing. Offline evaluation uses reserved datasets during development, while
continuous monitoring checks production performance.
[cleverx](https://cleverx.com/blog/what-is-modal-evaluation-in-machine-learning)

## Main Metrics

- Classification: Accuracy, precision, recall, F1-score (from confusion matrix).
  [iguazio](https://www.iguazio.com/glossary/model-evaluation/)
- Regression: Mean absolute error (MAE), root mean squared error (RMSE).
  [iguazio](https://www.iguazio.com/glossary/model-evaluation/)

| Task Type      | Example Metrics                 | Use Case                                                                                   |
| -------------- | ------------------------------- | ------------------------------------------------------------------------------------------ |
| Classification | Accuracy, Precision, Recall, F1 | Binary/multiclass prediction [iguazio](https://www.iguazio.com/glossary/model-evaluation/) |
| Regression     | MAE, RMSE, RÂ²                   | Continuous value forecasting [iguazio](https://www.iguazio.com/glossary/model-evaluation/) |
